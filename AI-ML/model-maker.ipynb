{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install torchtext\n",
    "# !pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import Dataset\n",
    "import torch.nn.functional as f\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "import torchtext.transforms as T\n",
    "\n",
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "import polars as pl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "max_len = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = pl.read_csv('./data/Latest_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pl.read_csv('./data/final_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (3_999_998, 2)\n",
      "┌───────────┬─────────────────────────────────┐\n",
      "│ sentiment ┆ review                          │\n",
      "│ ---       ┆ ---                             │\n",
      "│ i64       ┆ str                             │\n",
      "╞═══════════╪═════════════════════════════════╡\n",
      "│ 1         ┆ I'm reading a lot of reviews s… │\n",
      "│ 1         ┆ This soundtrack is my favorite… │\n",
      "│ 1         ┆ I truly like this soundtrack a… │\n",
      "│ 1         ┆ If you've played the game, you… │\n",
      "│ 1         ┆ I am quite sure any of you act… │\n",
      "│ …         ┆ …                               │\n",
      "│ 0         ┆ We bought this Thomas for our … │\n",
      "│ 0         ┆ My son recieved this as a birt… │\n",
      "│ 0         ┆ I bought this toy for my son w… │\n",
      "│ 1         ┆ This is a compilation of a wid… │\n",
      "│ 0         ┆ This DVD will be a disappointm… │\n",
      "└───────────┴─────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3999998"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([  101,  2023,  2001,  1037,  2307,  2338,  1010,  1045,  2074,  2071,\n",
      "         2025,  2404,  2009,  2091,  1010,  1998,  2071,  2025,  3191,  2009,\n",
      "         3435,  2438,  1012,  2879,  2054,  1037,  2338,  1996,  9792,  1998,\n",
      "         4332,  1999,  2023,  2074,  7906,  2017, 16986,  1998,  5782,  2000,\n",
      "         2113,  2054,  2003,  2183,  2000,  4148,  2279,  1012,  2023,  2338,\n",
      "         3084,  2017,  2991,  1999,  2293,  1998,  2064,  3684,  2017,  2039,\n",
      "         1010,  2009,  2064,  2036,  2191,  2017,  2061,  4963,  2100,  1012,\n",
      "         2023,  2338,  2064,  2191,  2017,  2175, 16215, 22494,  2195,  1997,\n",
      "         2115,  6699,  1012,  2023,  2003,  1037,  4248,  3191,  7472,  1012,\n",
      "         2009,  2003,  2242,  2008,  2017,  2097,  2215,  2000,  2203,  2115,\n",
      "         2154,  2125,  2007,  2065,  2017,  3191,  2012,  2305,  1012,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0])\n"
     ]
    }
   ],
   "source": [
    "tokens = tokenizer(\n",
    "            dataset[10, 1], \n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            max_length=128,  \n",
    "            return_tensors='pt'\n",
    "        )\n",
    "\n",
    "print(tokens['input_ids'].squeeze(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the Datasets to Pytorch Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    'train' : './data/Latest_train.csv',\n",
    "    'test' : './data/Latest_test.csv'\n",
    "}\n",
    "\n",
    "class ReviewDataset(Dataset):\n",
    "    def __init__(self, train = True):\n",
    "        super().__init__()\n",
    "        self.data = pl.read_csv(config['train'] if train else config['test'])\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        text = self.data[index, 1]\n",
    "        label = self.data[index, 0]\n",
    "        \n",
    "        tokens = self.tokenizer(\n",
    "            text, \n",
    "            padding='max_length', \n",
    "            truncation=True, \n",
    "            max_length=128,\n",
    "            return_tensors='pt'\n",
    "        )\n",
    "        \n",
    "        return (tokens['input_ids'].squeeze(0), label)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([  101,  2023,  2001,  1037,  2307,  2338,  1010,  1045,  2074,  2071,\n",
      "         2025,  2404,  2009,  2091,  1010,  1998,  2071,  2025,  3191,  2009,\n",
      "         3435,  2438,  1012,  2879,  2054,  1037,  2338,  1996,  9792,  1998,\n",
      "         4332,  1999,  2023,  2074,  7906,  2017, 16986,  1998,  5782,  2000,\n",
      "         2113,  2054,  2003,  2183,  2000,  4148,  2279,  1012,  2023,  2338,\n",
      "         3084,  2017,  2991,  1999,  2293,  1998,  2064,  3684,  2017,  2039,\n",
      "         1010,  2009,  2064,  2036,  2191,  2017,  2061,  4963,  2100,  1012,\n",
      "         2023,  2338,  2064,  2191,  2017,  2175, 16215, 22494,  2195,  1997,\n",
      "         2115,  6699,  1012,  2023,  2003,  1037,  4248,  3191,  7472,  1012,\n",
      "         2009,  2003,  2242,  2008,  2017,  2097,  2215,  2000,  2203,  2115,\n",
      "         2154,  2125,  2007,  2065,  2017,  3191,  2012,  2305,  1012,   102,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0]), 1)\n",
      "3599999\n"
     ]
    }
   ],
   "source": [
    "data_train = ReviewDataset(train=True)\n",
    "print(data_train[10])\n",
    "print(len(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([  101,  2065,  2017,  2215,  2000,  4952,  2000,  3449,  3804,  1010,\n",
      "         2059,  2009,  2003,  2488,  2065,  2017,  2031,  3229,  2000,  2010,\n",
      "         6457,  1010,  2023,  2003,  2025,  2032,  1010,  2009,  2003,  1037,\n",
      "        21025,  7382,  6799,  1010,  2200,  2092, 23339,  1012,   102,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
      "            0,     0,     0,     0,     0,     0,     0,     0]), 0)\n",
      "399999\n"
     ]
    }
   ],
   "source": [
    "data_test = ReviewDataset(train=False)\n",
    "print(data_test[10])\n",
    "print(len(data_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = DataLoader(data_train, batch_size=16, shuffle=True)\n",
    "dataset_test = DataLoader(data_test, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"I'm\",\n",
       " 'reading',\n",
       " 'a',\n",
       " 'lot',\n",
       " 'of',\n",
       " 'reviews',\n",
       " 'saying',\n",
       " 'that',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'best',\n",
       " \"'game\",\n",
       " \"soundtrack'\",\n",
       " 'and',\n",
       " 'I',\n",
       " 'figured',\n",
       " 'that',\n",
       " \"I'd\",\n",
       " 'write',\n",
       " 'a',\n",
       " 'review',\n",
       " 'to',\n",
       " 'disagree',\n",
       " 'a',\n",
       " 'bit.',\n",
       " 'This',\n",
       " 'in',\n",
       " 'my',\n",
       " 'opinino',\n",
       " 'is',\n",
       " 'Yasunori',\n",
       " \"Mitsuda's\",\n",
       " 'ultimate',\n",
       " 'masterpiece.',\n",
       " 'The',\n",
       " 'music',\n",
       " 'is',\n",
       " 'timeless',\n",
       " 'and',\n",
       " \"I'm\",\n",
       " 'been',\n",
       " 'listening',\n",
       " 'to',\n",
       " 'it',\n",
       " 'for',\n",
       " 'years',\n",
       " 'now',\n",
       " 'and',\n",
       " 'its',\n",
       " 'beauty',\n",
       " 'simply',\n",
       " 'refuses',\n",
       " 'to',\n",
       " 'fade.The',\n",
       " 'price',\n",
       " 'tag',\n",
       " 'on',\n",
       " 'this',\n",
       " 'is',\n",
       " 'pretty',\n",
       " 'staggering',\n",
       " 'I',\n",
       " 'must',\n",
       " 'say,',\n",
       " 'but',\n",
       " 'if',\n",
       " 'you',\n",
       " 'are',\n",
       " 'going',\n",
       " 'to',\n",
       " 'buy',\n",
       " 'any',\n",
       " 'cd',\n",
       " 'for',\n",
       " 'this',\n",
       " 'much',\n",
       " 'money,',\n",
       " 'this',\n",
       " 'is',\n",
       " 'the',\n",
       " 'only',\n",
       " 'one',\n",
       " 'that',\n",
       " 'I',\n",
       " 'feel',\n",
       " 'would',\n",
       " 'be',\n",
       " 'worth',\n",
       " 'every',\n",
       " 'penny.']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data[0, 1].split()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building Vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(['reading', \"I'm\"], 'a'), (['a', 'reading'], 'lot'), (['lot', 'a'], 'of')]\n",
      "70\n"
     ]
    }
   ],
   "source": [
    "CONTEXT_SIZE = 2\n",
    "\n",
    "test_sentence = training_data[0, 1].split()\n",
    "\n",
    "ngrams = [\n",
    "    (\n",
    "        [test_sentence[i - j - 1] for j in range(CONTEXT_SIZE)],\n",
    "        test_sentence[i]\n",
    "    )\n",
    "    for i in range(CONTEXT_SIZE, len(test_sentence))\n",
    "]\n",
    "# Print the first 3, just so you can see what they look like.\n",
    "print(ngrams[:3])\n",
    "\n",
    "vocab = set(test_sentence)\n",
    "print(len(vocab))\n",
    "word_to_ix = {word: i for i, word in enumerate(vocab)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = get_tokenizer('basic_english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def yield_tokens(data_iter):\n",
    "    for i in range(len(data_iter)):\n",
    "        yield tokenizer(data_iter[i, 1])\n",
    "    \n",
    "vocab = build_vocab_from_iterator(\n",
    "    yield_tokens(training_data),\n",
    "    min_freq = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "489763\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
